{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine_Index_All.ipynb         Local_Comp.ipynb\n",
      "Cosine_Scores_Saksh_Menon.csv  Window_Vectors_Saksh_Menon.csv\n",
      "Cosine_index_corr.ipynb        cosine_pipeline.ipynb\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "file_path = '/Users/sakshmenon/Downloads/cacna1a_wt_2597v_gpu_residue.rounded.csv'\n",
    "MAX_WT_LEN = 2506\n",
    "\n",
    "# os.chdir('Cosine Branch')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_protein_and_position(row):\n",
    "    protein_name = row[-2]\n",
    "    position_info = row[-1]\n",
    "    amino_acid = position_info[0]  # First character is the amino acid\n",
    "    position = int(position_info[1:])  # Rest of the string is the position\n",
    "    return protein_name, amino_acid, position\n",
    "\n",
    "# Function to extract the mutation status from the protein name\n",
    "def extract_mutation_status(protein_name):\n",
    "    if \"|\" in protein_name:\n",
    "        status = protein_name.split('|')[-1]\n",
    "        return 0 if status == 'nan' else 1\n",
    "    return 0\n",
    "\n",
    "def compute_cosine_similarity(vec1, vec2):\n",
    "    return cosine_similarity([vec1], [vec2])[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wild_Type_Vectors():\n",
    "    mt_flag = 0\n",
    "    wt_rows = []\n",
    "    mutated_rows = []\n",
    "    mutated_file_count = 0\n",
    "    max_mutated_rows_size = 600000  # Threshold to save to a file\n",
    "\n",
    "    # Open the file and read line by line\n",
    "    file =  open(file_path, 'r')\n",
    "    reader = csv.reader(file)\n",
    "    header = next(reader)  # Skip the header row\n",
    "\n",
    "    # Iterate over each row in the CSV file\n",
    "    for row in reader:\n",
    "        # Extract the protein name and position\n",
    "        protein_name, amino_acid, position = parse_protein_and_position(row)\n",
    "\n",
    "        # Convert the fractional columns to a numpy array (all columns except the last two)\n",
    "        vector = np.array(row[:-2], dtype=float)\n",
    "\n",
    "        # Extract mutation status\n",
    "        mutation_status = extract_mutation_status(protein_name)\n",
    "\n",
    "        # If it's a WT (wild-type) protein\n",
    "        if protein_name.startswith('>WT|'):\n",
    "            # Store the WT vector by position\n",
    "            wt_rows.append({'AA': amino_acid, 'Pos': position, 'Vector': vector, 'Status': mutation_status})\n",
    "            if len(wt_rows) == MAX_WT_LEN:\n",
    "                reader2 = csv.reader(file)\n",
    "                return reader2, pd.DataFrame(wt_rows)\n",
    "\n",
    "def Mutated_Type_Comp(reader, wt_df):\n",
    "    c=0\n",
    "    results = []\n",
    "    with open('Cosine_Scores_Saksh_Menon.csv', 'w') as csv_file:\n",
    "        csv_file.write('AA-Position-AA,Cosine Score,Label,Origin Mutation\\n')\n",
    "        for row in reader:\n",
    "            c+=1\n",
    "            protein_name, amino_acid, position = parse_protein_and_position(row)\n",
    "\n",
    "            # Convert the fractional columns to a numpy array (all columns except the last two)\n",
    "            vector = np.array(row[:-2], dtype=float)\n",
    "\n",
    "            # Extract mutation status\n",
    "            mutation_status = extract_mutation_status(protein_name)\n",
    "            \n",
    "            match = re.search(r'>\\w(\\d+)(\\w)\\|', protein_name)\n",
    "            if match:\n",
    "                mutant_name = f\"{match.group(2)}{match.group(1)}\"  # Extract the position and the new amino acid\n",
    "                \n",
    "                mutated_row = {'AA': amino_acid, 'Pos': position, 'Vector': vector, 'Status': mutation_status}\n",
    "\n",
    "                position = mutated_row['Pos']\n",
    "                mutated_vector = mutated_row['Vector']\n",
    "                amino_acid = mutated_row['AA']\n",
    "                status = mutated_row['Status']\n",
    "                origin = re.findall(r'>\\w\\d+\\w\\|', protein_name)[0][1:-1]\n",
    "\n",
    "                # Find the corresponding WT row by position\n",
    "                wt_row = wt_df.loc[position - 1]\n",
    "\n",
    "                if not(wt_row.empty):\n",
    "                    wt_vector = wt_row['Vector']\n",
    "                    wt_amino_acid = wt_row['AA']\n",
    "\n",
    "                    # Compute cosine similarity between WT and mutated vector\n",
    "                    similarity = compute_cosine_similarity(wt_vector, mutated_vector)\n",
    "                    # Store results with position, similarity, WT amino acid, mutation amino acid, and status\n",
    "                    # result = np.array([f\"{wt_amino_acid}{position}{amino_acid}\", similarity, status, origin], dtype = object)\n",
    "                    # results.append(result)\n",
    "                    csv_file.write(str(wt_amino_acid) + str(position) + str(amino_acid) + \",\" + str(similarity) + \",\" + str(status) + \",\" + str(origin)+\"\\n\")\n",
    "\n",
    "                \n",
    "                # if c==10:\n",
    "                #     return results\n",
    "\n",
    "        # Create a DataFrame to store the results\n",
    "        # result_df = pd.DataFrame(results, columns=['Mutant', 'CosineSim', 'Status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader, wt_df = Wild_Type_Vectors()\n",
    "res = Mutated_Type_Comp(reader, wt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_df = pd.read_csv(\"/Users/sakshmenon/Desktop/PLM CSV/Cosine_Scores_Saksh_Menon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def generate_flank_vectors(df, window_size, flank=3):\n",
    "    \"\"\"\n",
    "    Function to generate vectors of size (2 * flank + window_size) centered around every value in the DataFrame.\n",
    "    Pads with 0s if the value is too close to the edges of the sequence.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing only the values (one column expected).\n",
    "                           Each value's index is treated as its position.\n",
    "        window_size (int): The size of the central window around the mutation position.\n",
    "        flank (int): Number of residues to retrieve on each side of the central window (default=3).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of numpy arrays, where each array is a flanking vector centered around a value.\n",
    "    \"\"\"\n",
    "    flanked_vectors = []\n",
    "    file_name = '/Users/sakshmenon/Desktop/PLM CSV/Window_Vectors_Saksh_Menon_' + str(window_size) + '_.csv'\n",
    "\n",
    "    with open(file_name, 'w') as window_csv:\n",
    "        # mv = []\n",
    "\n",
    "        header = ''\n",
    "        for i in range(2*flank+window_size):\n",
    "            header += 'v' + str(i+1) + \",\"\n",
    "        header += 'Label,AA-Position-AA,Origin Mutation\\n'\n",
    "\n",
    "        window_csv.write(header)\n",
    "    # Iterate through each index (treated as position) and value in the DataFrame\n",
    "        for index, row in df.iterrows():\n",
    "            vector = df.iloc[:, 1].values  # Get the full sequence as a numpy array\n",
    "            position = index  # Treat the current index as the mutation position (0-based)\n",
    "\n",
    "            # The central window spans `window_size`, and we add `flank` on both sides\n",
    "            total_size = 2 * flank + window_size\n",
    "\n",
    "            # Compute start and end indices for the flanking region (including window)\n",
    "            start = max(0, position - (flank + int(window_size/2)))\n",
    "            end = min(len(vector), position + int(window_size/2) + flank + 1)\n",
    "\n",
    "            # Retrieve the region around the mutation, adjusting for window and flank\n",
    "            flank_vector = vector[start:end]\n",
    "\n",
    "            # Pad with 0s if necessary to ensure the vector is of size (2 * flank + window_size)\n",
    "            if len(flank_vector) < total_size:\n",
    "                pad_left = abs(start - (position - (flank + int(window_size/2))))  # Padding on the left if close to the start\n",
    "                pad_right = abs(end - (position + flank + int(window_size/2) + 1))  # Padding on the right if close to the end\n",
    "                flank_vector = np.pad(flank_vector, (pad_left, pad_right), 'constant', constant_values=0)\n",
    "\n",
    "            flanked_vectors.append(flank_vector)\n",
    "\n",
    "            flank_vector = np.array(flank_vector).tolist()\n",
    "            flank_vector.append(row['Label'])\n",
    "            \n",
    "            csv_line = str(flank_vector)[1:-1]\n",
    "            csv_line += \", \" + row['AA-Position-AA'] + \", \" + row['Origin Mutation'] + \"\\n\"\n",
    "            # flanked_vectors.append(flank_vector)\n",
    "            window_csv.write(csv_line)\n",
    "        \n",
    "    return flanked_vectors\n",
    "\n",
    "# Output the result\n",
    "# for vec in flank_vectors:\n",
    "#     print(vec)\n",
    "# flank_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 7\n",
    "flank_size = 3\n",
    "flank_vectors = generate_flank_vectors(cosine_df, window_size, flank_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
