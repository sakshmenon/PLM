{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>Label</th>\n",
       "      <th>AA-Position-AA</th>\n",
       "      <th>Origin Mutation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.992651</td>\n",
       "      <td>0.830556</td>\n",
       "      <td>0.988004</td>\n",
       "      <td>0.997248</td>\n",
       "      <td>0.997013</td>\n",
       "      <td>0.990613</td>\n",
       "      <td>1</td>\n",
       "      <td>A2S</td>\n",
       "      <td>A2S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.990311</td>\n",
       "      <td>0.791399</td>\n",
       "      <td>0.981248</td>\n",
       "      <td>0.993187</td>\n",
       "      <td>0.993757</td>\n",
       "      <td>0.985666</td>\n",
       "      <td>1</td>\n",
       "      <td>A2V</td>\n",
       "      <td>A2V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.974852</td>\n",
       "      <td>0.937129</td>\n",
       "      <td>0.625089</td>\n",
       "      <td>0.969650</td>\n",
       "      <td>0.980857</td>\n",
       "      <td>0.983931</td>\n",
       "      <td>0.975268</td>\n",
       "      <td>1</td>\n",
       "      <td>R3C</td>\n",
       "      <td>R3C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.988129</td>\n",
       "      <td>0.948764</td>\n",
       "      <td>0.705138</td>\n",
       "      <td>0.971007</td>\n",
       "      <td>0.985740</td>\n",
       "      <td>0.989563</td>\n",
       "      <td>0.982523</td>\n",
       "      <td>1</td>\n",
       "      <td>R3G</td>\n",
       "      <td>R3G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10028</th>\n",
       "      <td>0.991859</td>\n",
       "      <td>0.972531</td>\n",
       "      <td>0.966203</td>\n",
       "      <td>0.937991</td>\n",
       "      <td>0.630909</td>\n",
       "      <td>0.981387</td>\n",
       "      <td>0.987481</td>\n",
       "      <td>0.989263</td>\n",
       "      <td>0.984843</td>\n",
       "      <td>0</td>\n",
       "      <td>G5V</td>\n",
       "      <td>G5V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             v1        v2        v3        v4        v5        v6        v7  \\\n",
       "1      0.000000  0.000000  0.000000  0.992651  0.830556  0.988004  0.997248   \n",
       "2507   0.999995  0.999990  0.999985  0.990311  0.791399  0.981248  0.993187   \n",
       "5014   0.999990  0.999984  0.974852  0.937129  0.625089  0.969650  0.980857   \n",
       "7520   0.999958  0.999925  0.988129  0.948764  0.705138  0.971007  0.985740   \n",
       "10028  0.991859  0.972531  0.966203  0.937991  0.630909  0.981387  0.987481   \n",
       "\n",
       "             v8        v9  Label AA-Position-AA Origin Mutation  \n",
       "1      0.997013  0.990613      1            A2S             A2S  \n",
       "2507   0.993757  0.985666      1            A2V             A2V  \n",
       "5014   0.983931  0.975268      1            R3C             R3C  \n",
       "7520   0.989563  0.982523      1            R3G             R3G  \n",
       "10028  0.989263  0.984843      0            G5V             G5V  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "DATASET_RATIO = 0.57 #pos:neg\n",
    "window_size = 3\n",
    "flank = 3\n",
    "\n",
    "csv_dataset = '/Users/sakshmenon/Desktop/PLM CSV/Window_Vectors_Saksh_Menon_' + str(window_size) + '_.csv'\n",
    "dataset = pd.read_csv(csv_dataset)\n",
    "concentrated_dataset = dataset[dataset['Origin Mutation'] == dataset['AA-Position-AA']]\n",
    "concentrated_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2593, 12)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concentrated_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.copy()\n",
    "\n",
    "positive_vector = []\n",
    "negative_vector = []\n",
    "\n",
    "for label in enumerate(df['Label']):\n",
    "    if label[1] == 1:\n",
    "        positive_vector.append(df.loc[label[0]])\n",
    "    else:\n",
    "        negative_vector.append(df.loc[label[0]])\n",
    "\n",
    "pos_df = pd.DataFrame(positive_vector)\n",
    "pos_df = pos_df.reset_index()\n",
    "neg_df = pd.DataFrame(negative_vector)\n",
    "neg_df = neg_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_neg, x_test_neg, y_train_neg, y_test_neg = train_test_split(neg_df.index.tolist(), neg_df['Label'], random_state=32, test_size = 0.2)\n",
    "x_train_pos, x_test_pos, y_train_pos, y_test_pos = train_test_split(pos_df.index.tolist(), pos_df['Label'], random_state=32, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder = [{'v1': neg_df.v1[i],'v2': neg_df.v2[i],'v3': neg_df.v3[i], 'Label': neg_df.Label[i] } for i in x_train_neg]\n",
    "training_df = pd.DataFrame(placeholder)\n",
    "rand_idx = np.random.choice(np.arange(0, len(training_df)), size=len(x_train_pos), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(rand_idx):\n\u001b[1;32m      2\u001b[0m     new_row \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m'\u001b[39m: neg_df\u001b[38;5;241m.\u001b[39mv1[i[\u001b[38;5;241m1\u001b[39m]],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv2\u001b[39m\u001b[38;5;124m'\u001b[39m: neg_df\u001b[38;5;241m.\u001b[39mv2[i[\u001b[38;5;241m1\u001b[39m]],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv3\u001b[39m\u001b[38;5;124m'\u001b[39m: neg_df\u001b[38;5;241m.\u001b[39mv3[i[\u001b[38;5;241m1\u001b[39m]], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m: neg_df\u001b[38;5;241m.\u001b[39mLabel[i[\u001b[38;5;241m1\u001b[39m]]}])\n\u001b[0;32m----> 3\u001b[0m     training_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtraining_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/reshape/concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/concat.py:177\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    167\u001b[0m vals \u001b[38;5;241m=\u001b[39m [ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units]\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_extension:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# _is_uniform_join_units ensures a single dtype, so\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m#  we can use np.concatenate, which is more performant\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# expected \"Union[_SupportsArray[dtype[Any]],\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# _NestedSequence[_SupportsArray[dtype[Any]]]]\"\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_1d_only_ea_dtype(blk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m concat_compat(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ea_compat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in enumerate(rand_idx):\n",
    "    new_row = pd.DataFrame([{'v1': neg_df.v1[i[1]],'v2': neg_df.v2[i[1]],'v3': neg_df.v3[i[1]], 'Label': neg_df.Label[i[1]]}])\n",
    "    training_df = pd.concat([training_df.iloc[:i[1]], new_row, training_df.iloc[i[1]:]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder = [{'v1': neg_df.v1[i],'v2': neg_df.v2[i],'v3': neg_df.v3[i], 'Label': neg_df.Label[i] } for i in x_test_neg]\n",
    "testing_df = pd.DataFrame(placeholder)\n",
    "rand_idx = np.random.choice(np.arange(0, len(testing_df)), size=len(x_test_pos), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in enumerate(rand_idx):\n",
    "    new_row = pd.DataFrame({'v1': pos_df.v2[i],'v2': pos_df.v2[i],'v3': pos_df.v3[i], 'Label': pos_df.Label[i]})\n",
    "    testing_df = pd.concat([testing_df.iloc[:i[1]], new_row, testing_df.iloc[i[1]:]], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_split(df):\n",
    "    positive_vector = []\n",
    "    negative_vector = []\n",
    "\n",
    "    for label in enumerate(df['Label']):\n",
    "        if label[1] == 1:\n",
    "            positive_vector.append(df.loc[label[0]])\n",
    "        else:\n",
    "            negative_vector.append(df.loc[label[0]])\n",
    "\n",
    "    pos_df = pd.DataFrame(positive_vector)\n",
    "    neg_df = pd.DataFrame(negative_vector)\n",
    "\n",
    "    x_train_neg, x_test_neg, y_train_neg, y_test_neg = train_test_split(neg_df.index.tolist(), neg_df['Label'], random_state=32, test_size = 0.2)\n",
    "    x_train_pos, x_test_pos, y_train_pos, y_test_pos = train_test_split(pos_df.index.tolist(), pos_df['Label'], random_state=32, test_size = 0.2)\n",
    "\n",
    "    #80%\n",
    "    placeholder = [{'v1': neg_df.v1[i],'v2': neg_df.v2[i],'v3': neg_df.v3[i], 'Label': neg_df.Label[i] } for i in x_train_neg]\n",
    "    training_df = pd.DataFrame(placeholder)\n",
    "    rand_idx = np.random.choice(np.arange(0, len(training_df)), size=len(x_train_pos), replace=False)\n",
    "\n",
    "    for i in enumerate(rand_idx):\n",
    "        new_row = pd.DataFrame({'v1': neg_df.v2[i],'v2': neg_df.v2[i],'v3': neg_df.v3[i], 'Label': neg_df.Label[i]})\n",
    "        training_df = pd.concat([training_df.iloc[:i[1]], new_row, training_df.iloc[i[1]:]], ignore_index=True)\n",
    "    \n",
    "\n",
    "    placeholder = [{'v1': neg_df.v1[i],'v2': neg_df.v2[i],'v3': neg_df.v3[i], 'Label': neg_df.Label[i] } for i in x_test_neg]\n",
    "    testing_df = pd.DataFrame(placeholder)\n",
    "    rand_idx = np.random.choice(np.arange(0, len(testing_df)), size=len(x_test_pos), replace=False)\n",
    "\n",
    "    for i in enumerate(rand_idx):\n",
    "        new_row = pd.DataFrame({'v1': pos_df.v2[i],'v2': pos_df.v2[i],'v3': pos_df.v3[i], 'Label': pos_df.Label[i]})\n",
    "        testing_df = pd.concat([testing_df.iloc[:i[1]], new_row, testing_df.iloc[i[1]:]], ignore_index=True)\n",
    "\n",
    "    return training_df, testing_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'key of type tuple not found and not a MultiIndex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training, testing \u001b[38;5;241m=\u001b[39m \u001b[43mvec_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 23\u001b[0m, in \u001b[0;36mvec_split\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     20\u001b[0m rand_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(training_df)), size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(x_train_pos), replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(rand_idx):\n\u001b[0;32m---> 23\u001b[0m     new_row \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mneg_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv2\u001b[39m\u001b[38;5;124m'\u001b[39m: neg_df\u001b[38;5;241m.\u001b[39mv2[i],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv3\u001b[39m\u001b[38;5;124m'\u001b[39m: neg_df\u001b[38;5;241m.\u001b[39mv3[i], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m: neg_df\u001b[38;5;241m.\u001b[39mLabel[i]})\n\u001b[1;32m     24\u001b[0m     training_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([training_df\u001b[38;5;241m.\u001b[39miloc[:i[\u001b[38;5;241m1\u001b[39m]], new_row, training_df\u001b[38;5;241m.\u001b[39miloc[i[\u001b[38;5;241m1\u001b[39m]:]], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m placeholder \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m'\u001b[39m: neg_df\u001b[38;5;241m.\u001b[39mv1[i],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv2\u001b[39m\u001b[38;5;124m'\u001b[39m: neg_df\u001b[38;5;241m.\u001b[39mv2[i],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv3\u001b[39m\u001b[38;5;124m'\u001b[39m: neg_df\u001b[38;5;241m.\u001b[39mv3[i], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m: neg_df\u001b[38;5;241m.\u001b[39mLabel[i] } \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m x_test_neg]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1153\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rows_with_mask(key)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1163\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexing a Series with DataFrame is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported, use the appropriate DataFrame column\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1161\u001b[0m     )\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m-> 1163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_values_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key):\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;66;03m# e.g. scalars that aren't recognized by lib.is_scalar, GH#32684\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[key]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1207\u001b[0m, in \u001b[0;36mSeries._get_values_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[0;32m-> 1207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey of type tuple not found and not a MultiIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;66;03m# If key is contained, would have returned by now\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m indexer, new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc_level(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'key of type tuple not found and not a MultiIndex'"
     ]
    }
   ],
   "source": [
    "training, testing = vec_split(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- plots of variant only vs label,\\n- try one of these models:\\n- SVM(RBF)\\n- XGBoost\\n- Ridge\\n- LASSO\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "- plots of variant only vs label,\n",
    "- try one of these models:\n",
    "- SVM(RBF)\n",
    "- XGBoost\n",
    "- Ridge\n",
    "- LASSO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Testing Vector Initializing\n",
    "Without Data Redistributing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
    "\n",
    "columns = ['v'+ str(i+1) for i in range(window_size + 2*flank)]\n",
    "\n",
    "X = concentrated_dataset[columns]\n",
    "Y = concentrated_dataset['Label']\n",
    "test_vector_size = 0.2\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = test_vector_size, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97095079, 0.9427711 , 0.93678875, 0.89752534, 0.55990629,\n",
       "       0.96200681, 0.95152137, 0.97797463, 0.97621225])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_test).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## SVC Model Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rbf SVM - Training Accuracy: 0.64\n",
      "Rbf SVM - Test Accuracy: 0.63\n",
      "MCC for Test subset: 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "kernels = ['rbf']\n",
    "for kernel in kernels:\n",
    "    svm_model = SVC(kernel=kernel, probability=True, random_state=32)\n",
    "    svm_model.fit(X_train, Y_train)\n",
    "    \n",
    "    train_score = svm_model.score(X_train, Y_train)\n",
    "    test_score = svm_model.score(X_test, Y_test)\n",
    "    print(f'{kernel.capitalize()} SVM - Training Accuracy: {train_score:.2f}')\n",
    "    print(f'{kernel.capitalize()} SVM - Test Accuracy: {test_score:.2f}')\n",
    "    \n",
    "    Y_pred_test = svm_model.predict(X_test)\n",
    "    mcc = matthews_corrcoef(Y_test, Y_pred_test)\n",
    "    print(f\"MCC for Test subset: {mcc:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## XGBoost Model Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Random Forest - Training Accuracy: 0.69\n",
      "XGBoost Random Forest - Test Accuracy: 0.62\n",
      "XGBoost Random Forest - MCC: -0.010\n",
      "\n",
      "Hyperparameters used in the XGBoost Random Forest model:\n",
      "colsample_bynode: 0.8\n",
      "learning_rate: 1.0\n",
      "reg_lambda: 1e-05\n",
      "subsample: 0.8\n",
      "objective: binary:logistic\n",
      "enable_categorical: False\n",
      "missing: nan\n",
      "random_state: 32\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBRFClassifier(random_state=32)\n",
    "xgb_model.fit(X_train, Y_train)\n",
    "\n",
    "train_score = xgb_model.score(X_train, Y_train)\n",
    "test_score = xgb_model.score(X_test, Y_test)\n",
    "print(f'XGBoost Random Forest - Training Accuracy: {train_score:.2f}')\n",
    "print(f'XGBoost Random Forest - Test Accuracy: {test_score:.2f}')\n",
    "\n",
    "Y_pred_test = xgb_model.predict(X_test)\n",
    "mcc = matthews_corrcoef(Y_test, Y_pred_test)\n",
    "print(f\"XGBoost Random Forest - MCC: {mcc:.3f}\")\n",
    "\n",
    "print(\"\\nHyperparameters used in the XGBoost Random Forest model:\")\n",
    "for param, value in xgb_model.get_params().items():\n",
    "    if value is not None:\n",
    "        print(f'{param}: {value}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ridge Model Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression - Training Accuracy: 0.64\n",
      "Ridge Regression - Test Accuracy: 0.63\n",
      "Ridge Regression - MCC: 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "# Initialize the Ridge classifier\n",
    "ridge_model = RidgeClassifier(random_state=123)\n",
    "\n",
    "# Train the Ridge model\n",
    "ridge_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_score = ridge_model.score(X_train, Y_train)\n",
    "test_score = ridge_model.score(X_test, Y_test)\n",
    "print(f'Ridge Regression - Training Accuracy: {train_score:.2f}')\n",
    "print(f'Ridge Regression - Test Accuracy: {test_score:.2f}')\n",
    "\n",
    "# Calculate Matthews Correlation Coefficient (MCC)\n",
    "Y_pred_test = ridge_model.predict(X_test)\n",
    "mcc = matthews_corrcoef(Y_test, Y_pred_test)\n",
    "print(f\"Ridge Regression - MCC: {mcc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Lasso Model Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression - Training Accuracy: 0.64\n",
      "Lasso Regression - Test Accuracy: 0.63\n",
      "Lasso Regression - MCC: 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lasso_model = LogisticRegression(penalty='l1', solver='liblinear', random_state=123)\n",
    "\n",
    "# Train the Lasso model\n",
    "lasso_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_score = lasso_model.score(X_train, Y_train)\n",
    "test_score = lasso_model.score(X_test, Y_test)\n",
    "print(f'Lasso Regression - Training Accuracy: {train_score:.2f}')\n",
    "print(f'Lasso Regression - Test Accuracy: {test_score:.2f}')\n",
    "\n",
    "# Calculate Matthews Correlation Coefficient (MCC)\n",
    "Y_pred_test = lasso_model.predict(X_test)\n",
    "mcc = matthews_corrcoef(Y_test, Y_pred_test)\n",
    "print(f\"Lasso Regression - MCC: {mcc:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
