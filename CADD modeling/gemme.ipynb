{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761ec7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to load GEMME scores and variant annotations to build a prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7bf691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3584e5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2506)\n",
      "         V1        V2        V3        V4        V5        V6        V7\n",
      "a -1.902288       NaN -1.801436 -1.775125 -0.184715 -0.715972 -0.320246\n",
      "c -1.902288 -1.274720 -1.801436 -1.775125 -0.892025 -1.226970 -1.226748\n",
      "d -1.902288 -1.897429 -1.775027 -1.902387 -0.202129       NaN -0.053653\n",
      "e -1.902288 -1.897429 -1.775027 -1.902387 -0.143644 -0.069703       NaN\n",
      "f -1.902288 -1.897429 -1.902288       NaN -1.166047 -1.314861 -1.566667\n",
      "g -1.902288 -1.897429 -1.902288 -1.902387       NaN -0.687261 -0.486660\n",
      "h -1.902288 -1.897429 -1.775027 -1.902387 -0.892495 -0.880362 -0.180419\n",
      "i -1.274720 -1.556523 -1.902288 -1.737903 -1.166047 -1.314861 -1.384619\n",
      "k -1.902288 -1.897429 -1.274720 -1.902387 -1.126510 -1.270916 -1.566667\n",
      "l -1.274720 -1.556523 -1.902288 -0.615258 -1.166047 -1.314861 -1.384619\n"
     ]
    }
   ],
   "source": [
    "# Load the GEMME data\n",
    "gemme = pd.read_csv(\"O00555/O00555_normPred_evolCombi.txt\", sep=\" \", header=0)\n",
    "\n",
    "print(gemme.shape)\n",
    "print(gemme.iloc[0:10,0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16a40e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              value\n",
      "count  47614.000000\n",
      "mean      -1.991261\n",
      "std        2.191271\n",
      "min       -9.009544\n",
      "25%       -3.190148\n",
      "50%       -1.023401\n",
      "75%       -0.284953\n",
      "max        0.581580\n"
     ]
    }
   ],
   "source": [
    "# optional step to review protein-wide stats\n",
    "\n",
    "# Flatten the dataframe\n",
    "gemme_combined = gemme.melt(var_name='variable', value_name='value')\n",
    "\n",
    "# Print summary statistics\n",
    "print(gemme_combined.describe())\n",
    "# print(f\"Mean={gemme_combined['value'].mean():.2f} SD={gemme_combined['value'].std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55972d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and process FASTA file\n",
    "def process_fasta_file(fasta_path):\n",
    "    # Read the FASTA file\n",
    "    fasta_sequences = list(SeqIO.parse(fasta_path, \"fasta\"))\n",
    "    \n",
    "    # Assuming only one sequence in the FASTA file\n",
    "    sequence = str(fasta_sequences[0].seq)\n",
    "    \n",
    "    # Split the sequence by amino acids and create a data frame\n",
    "    sequence_df = pd.DataFrame([list(sequence)])\n",
    "    \n",
    "    # Rename the columns to \"aminoacid+position\"\n",
    "    sequence_df.columns = [f\"{aa}{i+1}\" for i, aa in enumerate(sequence)]\n",
    "    \n",
    "    return sequence_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "deae1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a given fasta file and update GEMME scores\n",
    "sequence_df = process_fasta_file(\"O00555/O00555.fasta\")\n",
    "\n",
    "# Replace column names with the names from sequence_df\n",
    "gemme.columns = sequence_df.columns\n",
    "# Capitalize all row indexes to match mutation letter size\n",
    "gemme.index = gemme.index.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69c55df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         M1        A2        R3        F4        G5        D6        E7\n",
      "A -1.902288       NaN -1.801436 -1.775125 -0.184715 -0.715972 -0.320246\n",
      "C -1.902288 -1.274720 -1.801436 -1.775125 -0.892025 -1.226970 -1.226748\n",
      "D -1.902288 -1.897429 -1.775027 -1.902387 -0.202129       NaN -0.053653\n",
      "E -1.902288 -1.897429 -1.775027 -1.902387 -0.143644 -0.069703       NaN\n",
      "F -1.902288 -1.897429 -1.902288       NaN -1.166047 -1.314861 -1.566667\n",
      "G -1.902288 -1.897429 -1.902288 -1.902387       NaN -0.687261 -0.486660\n",
      "H -1.902288 -1.897429 -1.775027 -1.902387 -0.892495 -0.880362 -0.180419\n",
      "I -1.274720 -1.556523 -1.902288 -1.737903 -1.166047 -1.314861 -1.384619\n",
      "K -1.902288 -1.897429 -1.274720 -1.902387 -1.126510 -1.270916 -1.566667\n",
      "L -1.274720 -1.556523 -1.902288 -0.615258 -1.166047 -1.314861 -1.384619\n",
      "Index(['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(gemme.iloc[0:10,0:7])\n",
    "print(gemme.index[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87b585ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the variants to diseases annotation file from UniProt/ClinVar\n",
    "variants = pd.read_csv(\"O00555/O00555-variants.csv\")\n",
    "\n",
    "# Create a Disease column based on the Phenotype length\n",
    "variants['Disease'] = np.where(variants['Phenotype'].str.len() > 0, 1, 0)\n",
    "\n",
    "# Separate missense and other mutations\n",
    "pattern = r'^[A-Z][0-9]+[A-Z]$'\n",
    "variants_single = variants[variants['AAChange'].str.match(pattern)].copy()\n",
    "variants_nonsingle = variants[~variants['AAChange'].str.match(pattern)].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a7585a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600\n",
      "255\n",
      "   Position AAChange                                          Phenotype  \\\n",
      "0         2      A2S  Developmental and epileptic encephalopathy, 42...   \n",
      "1         2      A2V  Developmental and epileptic encephalopathy, 42...   \n",
      "2         3      R3C  Developmental and epileptic encephalopathy, 42...   \n",
      "3         3      R3G  Developmental and epileptic encephalopathy, 42...   \n",
      "4         5      G5V                                                NaN   \n",
      "5         8      M8I                                                NaN   \n",
      "6         9      P9L  Developmental and epileptic encephalopathy, 42...   \n",
      "7         9      P9S                                                NaN   \n",
      "8        10     A10S                                                NaN   \n",
      "9        10     A10V  Developmental and epileptic encephalopathy, 42...   \n",
      "\n",
      "   Disease  \n",
      "0        1  \n",
      "1        1  \n",
      "2        1  \n",
      "3        1  \n",
      "4        0  \n",
      "5        0  \n",
      "6        1  \n",
      "7        0  \n",
      "8        0  \n",
      "9        1  \n"
     ]
    }
   ],
   "source": [
    "print(len(variants_single))\n",
    "print(len(variants_nonsingle))\n",
    "\n",
    "print(variants_single.iloc[0:10,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7b5e6d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve a value by column and row name\n",
    "def get_gemme_score(address):\n",
    "    # Extract the column name (all except last character) and row name (last character)\n",
    "    col_name = address[:-1]\n",
    "    row_name = address[-1]\n",
    "    \n",
    "    # Retrieve the value from the dataframe\n",
    "    return gemme.at[row_name, col_name]\n",
    "\n",
    "# Add a new column to with retrieved values\n",
    "variants_single['GEMME'] = variants_single['AAChange'].apply(get_gemme_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "97b97089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total variants Benign=1655, Deleterious=945\n",
      "Of which those with GEMME score <= -2\n",
      "Benign= 192\n",
      "Deleterious= 217\n"
     ]
    }
   ],
   "source": [
    "# Bin the values into two buckets based on Disease value\n",
    "variants_single_benign = variants_single[variants_single['Disease'] == 0]\n",
    "variants_single_deleterious = variants_single[variants_single['Disease'] == 1]\n",
    "\n",
    "print(f\"Total variants Benign={variants_single_benign.shape[0]}, Deleterious={variants_single_deleterious.shape[0]}\")\n",
    "print(\"Of which those with GEMME score <= -2\")\n",
    "print(\"Benign=\",variants_single_benign[variants_single_benign['GEMME'] <= -2].shape[0])\n",
    "print(\"Deleterious=\",variants_single_deleterious[variants_single_deleterious['GEMME'] <= -2].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe7af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate Input Vectors Based on a Window -5 to +5 Around the Mutation Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "716ca735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "0595a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function for scaling\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Function to extract window -5 to +5 around the mutation position\n",
    "def extract_window_scores(row, gemme_df, window_size=5):\n",
    "    # Extract the position from AAChange (e.g., A123B -> 123)\n",
    "    position = int(row['AAChange'][1:-1]) - 1  # -1 because positions are 0-indexed in Python\n",
    "    \n",
    "    # Define the window range\n",
    "    start = max(0, position - window_size)\n",
    "    end = min(gemme_df.shape[1], position + window_size + 1)\n",
    "    \n",
    "    # Extract the window of GEMME scores (for all rows)\n",
    "    window_scores = gemme_df.iloc[:, start:end].values\n",
    "    \n",
    "    # Apply the sigmoid function to scale the GEMME values\n",
    "    window_scores = sigmoid(window_scores)\n",
    "    \n",
    "    # Check if the extracted window has the correct size\n",
    "    if window_scores.shape[1] < 2 * window_size + 1:\n",
    "        # Calculate necessary padding\n",
    "        padding_left = max(0, window_size - position)\n",
    "        padding_right = max(0, window_size - (gemme_df.shape[1] - position - 1))\n",
    "        \n",
    "        # Pad with NaN (or another value, if desired)\n",
    "        window_scores = np.pad(window_scores, ((0, 0), (padding_left, padding_right)), 'constant', constant_values=np.nan)\n",
    "    \n",
    "    # Replace NaN values with 1\n",
    "    window_scores = np.nan_to_num(window_scores, nan=1)\n",
    "    \n",
    "    # Flatten the window to create a 1D vector\n",
    "    window_scores = window_scores.flatten()\n",
    "    \n",
    "    # Extract the GEMME score for the mutation itself (before applying sigmoid)\n",
    "    gemme_score = row['GEMME']\n",
    "    \n",
    "    # Apply the sigmoid function to scale the GEMME score\n",
    "    gemme_score = sigmoid(gemme_score)\n",
    "    \n",
    "    # Add the GEMME score for the mutation itself as an additional feature\n",
    "    window_scores = np.append(window_scores, gemme_score)\n",
    "    \n",
    "    return window_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "d6aba0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row in variants_single to create input vectors\n",
    "ws = 5\n",
    "vectors = variants_single.apply(lambda row: extract_window_scores(row, gemme, window_size=ws), axis=1)\n",
    "\n",
    "# Convert the list of window scores into a numpy array\n",
    "X = np.array(vectors.tolist())\n",
    "Y = variants_single['Disease'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "c12f18fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2600, 221) (221,) (221,) [[1.         1.         1.         1.         0.1298497  1.\n",
      "  0.14167638 0.14490613 0.45395204 0.32828065 0.42061578 1.\n",
      "  1.         1.         1.         0.1298497  0.21845038 0.14167638\n",
      "  0.14490613 0.29069204 0.22671217 0.2267511  1.         1.\n",
      "  1.         1.         0.1298497  0.13039974 0.14491835 0.12983856\n",
      "  0.44963902 1.         0.48658986 1.         1.         1.\n",
      "  1.         0.1298497  0.13039974 0.14491835 0.12983856 0.46415069\n",
      "  0.48258132 1.         1.         1.         1.         1.\n",
      "  0.1298497  0.13039974 0.1298497  1.         0.2375703  0.21167453\n",
      "  0.17269199 1.         1.         1.         1.         0.1298497\n",
      "  0.13039974 0.1298497  0.12983856 1.         0.3346426  0.38068077\n",
      "  1.         1.         1.         1.         0.1298497  0.13039974\n",
      "  0.14491835 0.12983856 0.29059525 0.29310277 0.45501725 1.\n",
      "  1.         1.         1.         0.21845038 0.17414613 0.1298497\n",
      "  0.14957944 0.2375703  0.21167453 0.20026816 1.         1.\n",
      "  1.         1.         0.1298497  0.13039974 0.21845038 0.12983856\n",
      "  0.24480582 0.21910055 0.17269199 1.         1.         1.\n",
      "  1.         0.21845038 0.17414613 0.1298497  0.35086079 0.2375703\n",
      "  0.21167453 0.20026816 1.         1.         1.         1.\n",
      "  1.         0.17414613 0.1298497  0.14957944 0.2375703  0.21167453\n",
      "  0.20026816 1.         1.         1.         1.         0.1298497\n",
      "  0.13039974 0.2443796  0.12983856 0.37966469 0.48799894 0.45724124\n",
      "  1.         1.         1.         1.         0.1298497  0.37114635\n",
      "  0.1298497  0.12983856 0.2375703  0.21167453 0.17269199 1.\n",
      "  1.         1.         1.         0.1298497  0.13039974 0.14491835\n",
      "  0.12983856 0.29059525 0.46242607 0.25841697 1.         1.\n",
      "  1.         1.         0.1298497  0.13039974 1.         0.12983856\n",
      "  0.24480582 0.23682215 0.17269199 1.         1.         1.\n",
      "  1.         0.1298497  0.44835574 0.14167638 0.32773726 0.45161029\n",
      "  0.39090197 0.35289724 1.         1.         1.         1.\n",
      "  0.1298497  0.46015591 0.14167638 0.14490613 0.46517106 0.22671217\n",
      "  0.41958524 1.         1.         1.         1.         0.21845038\n",
      "  0.39684814 0.1298497  0.3074003  0.2375703  0.21167453 0.3883579\n",
      "  1.         1.         1.         1.         0.1298497  0.13039974\n",
      "  0.1298497  0.21845038 0.2375703  0.21167453 0.17269199 1.\n",
      "  1.         1.         1.         0.1298497  0.13039974 0.1298497\n",
      "  0.4785288  0.2375703  0.21167453 0.17269199 0.44835574]\n",
      " [1.         1.         1.         1.         0.1298497  1.\n",
      "  0.14167638 0.14490613 0.45395204 0.32828065 0.42061578 1.\n",
      "  1.         1.         1.         0.1298497  0.21845038 0.14167638\n",
      "  0.14490613 0.29069204 0.22671217 0.2267511  1.         1.\n",
      "  1.         1.         0.1298497  0.13039974 0.14491835 0.12983856\n",
      "  0.44963902 1.         0.48658986 1.         1.         1.\n",
      "  1.         0.1298497  0.13039974 0.14491835 0.12983856 0.46415069\n",
      "  0.48258132 1.         1.         1.         1.         1.\n",
      "  0.1298497  0.13039974 0.1298497  1.         0.2375703  0.21167453\n",
      "  0.17269199 1.         1.         1.         1.         0.1298497\n",
      "  0.13039974 0.1298497  0.12983856 1.         0.3346426  0.38068077\n",
      "  1.         1.         1.         1.         0.1298497  0.13039974\n",
      "  0.14491835 0.12983856 0.29059525 0.29310277 0.45501725 1.\n",
      "  1.         1.         1.         0.21845038 0.17414613 0.1298497\n",
      "  0.14957944 0.2375703  0.21167453 0.20026816 1.         1.\n",
      "  1.         1.         0.1298497  0.13039974 0.21845038 0.12983856\n",
      "  0.24480582 0.21910055 0.17269199 1.         1.         1.\n",
      "  1.         0.21845038 0.17414613 0.1298497  0.35086079 0.2375703\n",
      "  0.21167453 0.20026816 1.         1.         1.         1.\n",
      "  1.         0.17414613 0.1298497  0.14957944 0.2375703  0.21167453\n",
      "  0.20026816 1.         1.         1.         1.         0.1298497\n",
      "  0.13039974 0.2443796  0.12983856 0.37966469 0.48799894 0.45724124\n",
      "  1.         1.         1.         1.         0.1298497  0.37114635\n",
      "  0.1298497  0.12983856 0.2375703  0.21167453 0.17269199 1.\n",
      "  1.         1.         1.         0.1298497  0.13039974 0.14491835\n",
      "  0.12983856 0.29059525 0.46242607 0.25841697 1.         1.\n",
      "  1.         1.         0.1298497  0.13039974 1.         0.12983856\n",
      "  0.24480582 0.23682215 0.17269199 1.         1.         1.\n",
      "  1.         0.1298497  0.44835574 0.14167638 0.32773726 0.45161029\n",
      "  0.39090197 0.35289724 1.         1.         1.         1.\n",
      "  0.1298497  0.46015591 0.14167638 0.14490613 0.46517106 0.22671217\n",
      "  0.41958524 1.         1.         1.         1.         0.21845038\n",
      "  0.39684814 0.1298497  0.3074003  0.2375703  0.21167453 0.3883579\n",
      "  1.         1.         1.         1.         0.1298497  0.13039974\n",
      "  0.1298497  0.21845038 0.2375703  0.21167453 0.17269199 1.\n",
      "  1.         1.         1.         0.1298497  0.13039974 0.1298497\n",
      "  0.4785288  0.2375703  0.21167453 0.17269199 0.39684814]\n",
      " [1.         1.         1.         0.1298497  1.         0.14167638\n",
      "  0.14490613 0.45395204 0.32828065 0.42061578 0.47529027 1.\n",
      "  1.         1.         0.1298497  0.21845038 0.14167638 0.14490613\n",
      "  0.29069204 0.22671217 0.2267511  0.46221589 1.         1.\n",
      "  1.         0.1298497  0.13039974 0.14491835 0.12983856 0.44963902\n",
      "  1.         0.48658986 0.3511476  1.         1.         1.\n",
      "  0.1298497  0.13039974 0.14491835 0.12983856 0.46415069 0.48258132\n",
      "  1.         0.3511476  1.         1.         1.         0.1298497\n",
      "  0.13039974 0.1298497  1.         0.2375703  0.21167453 0.17269199\n",
      "  0.44146517 1.         1.         1.         0.1298497  0.13039974\n",
      "  0.1298497  0.12983856 1.         0.3346426  0.38068077 0.39741455\n",
      "  1.         1.         1.         0.1298497  0.13039974 0.14491835\n",
      "  0.12983856 0.29059525 0.29310277 0.45501725 0.3511476  1.\n",
      "  1.         1.         0.21845038 0.17414613 0.1298497  0.14957944\n",
      "  0.2375703  0.21167453 0.20026816 0.48139057 1.         1.\n",
      "  1.         0.1298497  0.13039974 0.21845038 0.12983856 0.24480582\n",
      "  0.21910055 0.17269199 0.35184858 1.         1.         1.\n",
      "  0.21845038 0.17414613 0.1298497  0.35086079 0.2375703  0.21167453\n",
      "  0.20026816 0.49246819 1.         1.         1.         1.\n",
      "  0.17414613 0.1298497  0.14957944 0.2375703  0.21167453 0.20026816\n",
      "  1.         1.         1.         1.         0.1298497  0.13039974\n",
      "  0.2443796  0.12983856 0.37966469 0.48799894 0.45724124 0.3511476\n",
      "  1.         1.         1.         0.1298497  0.37114635 0.1298497\n",
      "  0.12983856 0.2375703  0.21167453 0.17269199 0.45229609 1.\n",
      "  1.         1.         0.1298497  0.13039974 0.14491835 0.12983856\n",
      "  0.29059525 0.46242607 0.25841697 0.44908317 1.         1.\n",
      "  1.         0.1298497  0.13039974 1.         0.12983856 0.24480582\n",
      "  0.23682215 0.17269199 0.35406054 1.         1.         1.\n",
      "  0.1298497  0.44835574 0.14167638 0.32773726 0.45161029 0.39090197\n",
      "  0.35289724 0.36927188 1.         1.         1.         0.1298497\n",
      "  0.46015591 0.14167638 0.14490613 0.46517106 0.22671217 0.41958524\n",
      "  0.46120865 1.         1.         1.         0.21845038 0.39684814\n",
      "  0.1298497  0.3074003  0.2375703  0.21167453 0.3883579  0.49782507\n",
      "  1.         1.         1.         0.1298497  0.13039974 0.1298497\n",
      "  0.21845038 0.2375703  0.21167453 0.17269199 0.35014062 1.\n",
      "  1.         1.         0.1298497  0.13039974 0.1298497  0.4785288\n",
      "  0.2375703  0.21167453 0.17269199 0.42935827 0.14167638]]\n",
      "(2600,) [1 1 1 1 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X[0].shape, X[1000].shape, X[0:5][0:3])\n",
    "print(Y.shape, Y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a7614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split the Data into Training and Control Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "5e4a23cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets with a 70:30 ratio and stratification\n",
    "ts = 0.35\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=ts, stratify=Y, random_state=123)\n",
    "\n",
    "# Baseline accuracy: Assign all labels to the dominating class\n",
    "# Find the most frequent class in the training data\n",
    "most_frequent_class = np.bincount(Y_train).argmax()\n",
    "\n",
    "# Create a baseline prediction where all predictions are the most frequent class\n",
    "Y_baseline_pred = np.full_like(Y_test, most_frequent_class)\n",
    "\n",
    "# Calculate the baseline accuracy\n",
    "baseline_accuracy = accuracy_score(Y_test, Y_baseline_pred)\n",
    "print(f'Baseline Accuracy: {baseline_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b3a40fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train the Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4bc2f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===> SVM\n",
    "\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "29db156b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rbf SVM - Training Accuracy: 0.80\n",
      "Rbf SVM - Test Accuracy: 0.66\n",
      "MCC for Test subset: 0.189\n"
     ]
    }
   ],
   "source": [
    "# Re-train the SVM model using other kernels\n",
    "# kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "kernels = ['rbf']\n",
    "\n",
    "for kernel in kernels:\n",
    "    svm_model = SVC(kernel=kernel, probability=True, random_state=123)\n",
    "    svm_model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    train_score = svm_model.score(X_train, Y_train)\n",
    "    test_score = svm_model.score(X_test, Y_test)\n",
    "    print(f'{kernel.capitalize()} SVM - Training Accuracy: {train_score:.2f}')\n",
    "    print(f'{kernel.capitalize()} SVM - Test Accuracy: {test_score:.2f}')\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    Y_pred_test = svm_model.predict(X_test)\n",
    "    # Calculate Matthews Correlation Coefficient (MCC)\n",
    "    mcc = matthews_corrcoef(Y_test, Y_pred_test)\n",
    "    print(f\"MCC for Test subset: {mcc:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "35c3a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===> XGBoost\n",
    "\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "cd05acac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Random Forest - Training Accuracy: 0.77\n",
      "XGBoost Random Forest - Test Accuracy: 0.66\n",
      "XGBoost Random Forest - MCC: 0.202\n",
      "\n",
      "Hyperparameters used in the XGBoost Random Forest model:\n",
      "colsample_bynode: 0.8\n",
      "learning_rate: 1.0\n",
      "reg_lambda: 1e-05\n",
      "subsample: 0.8\n",
      "objective: binary:logistic\n",
      "enable_categorical: False\n",
      "missing: nan\n",
      "random_state: 123\n"
     ]
    }
   ],
   "source": [
    "# Initialize the XGBoost Random Forest classifier\n",
    "xgb_model = xgb.XGBRFClassifier(random_state=123)\n",
    "\n",
    "# Train the XGBoost Random Forest model\n",
    "xgb_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_score = xgb_model.score(X_train, Y_train)\n",
    "test_score = xgb_model.score(X_test, Y_test)\n",
    "print(f'XGBoost Random Forest - Training Accuracy: {train_score:.2f}')\n",
    "print(f'XGBoost Random Forest - Test Accuracy: {test_score:.2f}')\n",
    "\n",
    "# Calculate Matthews Correlation Coefficient (MCC)\n",
    "Y_pred_test = xgb_model.predict(X_test)\n",
    "mcc = matthews_corrcoef(Y_test, Y_pred_test)\n",
    "print(f\"XGBoost Random Forest - MCC: {mcc:.3f}\")\n",
    "\n",
    "# Print out the hyperparameters used\n",
    "print(\"\\nHyperparameters used in the XGBoost Random Forest model:\")\n",
    "for param, value in xgb_model.get_params().items():\n",
    "    if value is not None:\n",
    "        print(f'{param}: {value}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f3b473d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import uniform, randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2ed2f2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3840 candidates, totalling 19200 fits\n",
      "Best parameters found: {'colsample_bynode': 0.6, 'learning_rate': 1.0, 'max_depth': 5, 'n_estimators': 50, 'reg_lambda': 0.1, 'subsample': 0.7}\n",
      "Best cross-validation accuracy: 0.66\n",
      "Test Accuracy with best parameters: 0.67\n"
     ]
    }
   ],
   "source": [
    "# !!! Skip this cell as it takes a while with no major advantage in results\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],         # Number of trees in the forest\n",
    "    'max_depth': [2, 3, 5, 7],                   # Maximum depth of each tree\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5, 1.0], # Learning rate (step size shrinkage)\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9],           # Subsample ratio of the training instances\n",
    "    'colsample_bynode': [0.6, 0.7, 0.8, 0.9],    # Subsample ratio of columns when constructing each tree\n",
    "    'reg_lambda': [1e-05, 1e-03, 1e-01]          # L2 regularization term on weights\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize the XGBoost Random Forest classifier\n",
    "xgb_model = xgb.XGBRFClassifier(random_state=123)\n",
    "\n",
    "# Set up the grid search\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Best parameters found\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "\n",
    "# Best score achieved with the best parameters\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.2f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_score = grid_search.score(X_test, Y_test)\n",
    "print(f\"Test Accuracy with best parameters: {test_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8430b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===> Ridge Regression\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "612b56d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression - Training Accuracy: 0.72\n",
      "Ridge Regression - Test Accuracy: 0.64\n",
      "Ridge Regression - MCC: 0.158\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Ridge classifier\n",
    "ridge_model = RidgeClassifier(random_state=123)\n",
    "\n",
    "# Train the Ridge model\n",
    "ridge_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_score = ridge_model.score(X_train, Y_train)\n",
    "test_score = ridge_model.score(X_test, Y_test)\n",
    "print(f'Ridge Regression - Training Accuracy: {train_score:.2f}')\n",
    "print(f'Ridge Regression - Test Accuracy: {test_score:.2f}')\n",
    "\n",
    "# Calculate Matthews Correlation Coefficient (MCC)\n",
    "Y_pred_test = ridge_model.predict(X_test)\n",
    "mcc = matthews_corrcoef(Y_test, Y_pred_test)\n",
    "print(f\"Ridge Regression - MCC: {mcc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e1ac6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===> LASSO Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "e4c9a0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression - Training Accuracy: 0.72\n",
      "Lasso Regression - Test Accuracy: 0.65\n",
      "Lasso Regression - MCC: 0.173\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Lasso (L1-regularized Logistic Regression) classifier\n",
    "lasso_model = LogisticRegression(penalty='l1', solver='liblinear', random_state=123)\n",
    "\n",
    "# Train the Lasso model\n",
    "lasso_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_score = lasso_model.score(X_train, Y_train)\n",
    "test_score = lasso_model.score(X_test, Y_test)\n",
    "print(f'Lasso Regression - Training Accuracy: {train_score:.2f}')\n",
    "print(f'Lasso Regression - Test Accuracy: {test_score:.2f}')\n",
    "\n",
    "# Calculate Matthews Correlation Coefficient (MCC)\n",
    "Y_pred_test = lasso_model.predict(X_test)\n",
    "mcc = matthews_corrcoef(Y_test, Y_pred_test)\n",
    "print(f\"Lasso Regression - MCC: {mcc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516c9c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
